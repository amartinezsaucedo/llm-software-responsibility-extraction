version: '3'
services:
  llama-service:
    build: 
      context: .
      dockerfile: Dockerfile
    runtime: nvidia
    environment:
    - NVIDIA_VISIBLE_DEVICES=all
    - NVIDIA_DRIVER_CAPABILITIES=all
    container_name: llama
    ports:
      - 8888:8888
    volumes:
      - ./:/llama

volumes:
  llama: